{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf82033",
   "metadata": {},
   "source": [
    "## Importing the required libraries and loading the CSV file into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e681a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/shardul/PycharmProjects/GDSCML/Fuel.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ee56b",
   "metadata": {},
   "source": [
    "## Splitting the data into training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1) #Shuffles the dataframe\n",
    "train_ratio = 0.8    #Percentage of training data\n",
    "total_rows = df.shape[0]\n",
    "train_size = int(total_rows * train_ratio)\n",
    "train = df[0:train_size]\n",
    "test = df[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcfb87",
   "metadata": {},
   "source": [
    "## Analyzing the correlation between the predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d213031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          ENGINESIZE  CYLINDERS  FUELCONSUMPTION_CITY  \\\n",
      "ENGINESIZE                  1.000000   0.934011              0.832225   \n",
      "CYLINDERS                   0.934011   1.000000              0.796473   \n",
      "FUELCONSUMPTION_CITY        0.832225   0.796473              1.000000   \n",
      "FUELCONSUMPTION_HWY         0.778746   0.724594              0.965718   \n",
      "FUELCONSUMPTION_COMB        0.819482   0.776788              0.995542   \n",
      "FUELCONSUMPTION_COMB_MPG   -0.808554  -0.770430             -0.935613   \n",
      "CO2EMISSIONS                0.874154   0.849685              0.898039   \n",
      "\n",
      "                          FUELCONSUMPTION_HWY  FUELCONSUMPTION_COMB  \\\n",
      "ENGINESIZE                           0.778746              0.819482   \n",
      "CYLINDERS                            0.724594              0.776788   \n",
      "FUELCONSUMPTION_CITY                 0.965718              0.995542   \n",
      "FUELCONSUMPTION_HWY                  1.000000              0.985804   \n",
      "FUELCONSUMPTION_COMB                 0.985804              1.000000   \n",
      "FUELCONSUMPTION_COMB_MPG            -0.893809             -0.927965   \n",
      "CO2EMISSIONS                         0.861748              0.892129   \n",
      "\n",
      "                          FUELCONSUMPTION_COMB_MPG  CO2EMISSIONS  \n",
      "ENGINESIZE                               -0.808554      0.874154  \n",
      "CYLINDERS                                -0.770430      0.849685  \n",
      "FUELCONSUMPTION_CITY                     -0.935613      0.898039  \n",
      "FUELCONSUMPTION_HWY                      -0.893809      0.861748  \n",
      "FUELCONSUMPTION_COMB                     -0.927965      0.892129  \n",
      "FUELCONSUMPTION_COMB_MPG                  1.000000     -0.906394  \n",
      "CO2EMISSIONS                             -0.906394      1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[:, np.r_[4, 5, 8:13]].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8752a1",
   "metadata": {},
   "source": [
    "# All predictors have high correlation with CO2 emissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b64b1",
   "metadata": {},
   "source": [
    "## Creating training and test NumPy arrays of the predictor and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffa3599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:, np.r_[4, 5, 8:12]].to_numpy()\n",
    "y_train = train.iloc[:, 12].to_numpy()\n",
    "\n",
    "x_test = test.iloc[:, np.r_[4, 5, 8:12]].to_numpy()\n",
    "y_test = test.iloc[:, 12].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce1bb8a",
   "metadata": {},
   "source": [
    "## Function to add a column of 1s to the features vector to account for the intercept during matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4568adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateXvector(X):\n",
    "    vector = np.c_[np.ones((len(X), 1)), X]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ddd09",
   "metadata": {},
   "source": [
    "## Function to generate random initial parameters vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "372cb8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_init(X):\n",
    "    theta = np.random.randn(len(X[0]) + 1, 1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b0af1b",
   "metadata": {},
   "source": [
    "## Gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee669fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Descent(X, y, learningrate, epochs):\n",
    "    y_new = np.reshape(y, (len(y), 1))\n",
    "    vectorX = generateXvector(X)\n",
    "    theta = theta_init(X)\n",
    "    m = len(X)\n",
    "    for i in range(epochs):\n",
    "        gradients = 2 / m * vectorX.T.dot(vectorX.dot(theta) - y_new) #Gradient vector of cost function\n",
    "        theta = np.float128(theta - learningrate * gradients) #Updates parameters for each iteration\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74c042",
   "metadata": {},
   "source": [
    "## Scaling the data to remove the overflow errors occuring with unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "482a1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_transform_train=StandardScaler().fit_transform(x_train)\n",
    "X_transform_test=StandardScaler().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07fd3d",
   "metadata": {},
   "source": [
    "## Calling the gradient descent function and storing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b6cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learningrate = 0.0001\n",
    "epochs = 100000\n",
    "theta = Gradient_Descent(X_transform_train, y_train, learningrate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801f082",
   "metadata": {},
   "source": [
    "## Scikit-Learn Linear Regression to compare it with my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4349a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256.12661195779606 [ 13.21191318  14.31495668 -67.68265118 -18.4362907   93.57674929\n",
      " -29.18587943]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_transform_train, y_train)\n",
    "print(lin_reg.intercept_, lin_reg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cc654a",
   "metadata": {},
   "source": [
    "## R-squared and RMSE for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59bd3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of my model:  0.8865334319976048\n",
      "RMSE of my model:  20.382660249297304482\n",
      "Scikit-Learn R-squared:  0.8834353558272443\n",
      "Scikit-Learn RMSE:  20.65904906377307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"R-squared of my model: \", r2_score(y_test, X_transform_test.dot(theta[1:]) + theta[0]))\n",
    "print(\"RMSE of my model: \", np.sqrt(mean_squared_error(y_test, X_transform_test.dot(theta[1:]) + theta[0])))\n",
    "print(\"Scikit-Learn R-squared: \", r2_score(y_test, lin_reg.predict(X_transform_test)))\n",
    "print(\"Scikit-Learn RMSE: \", np.sqrt(mean_squared_error(y_test, lin_reg.predict(X_transform_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDSC",
   "language": "python",
   "name": "gdsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
